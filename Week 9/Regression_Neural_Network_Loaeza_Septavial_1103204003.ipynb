{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loaeza Septavial\n",
        "1103204003"
      ],
      "metadata": {
        "id": "UasRMcOXOz1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GToIRyPgOt8-"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/heart.csv')"
      ],
      "metadata": {
        "id": "pCBJRRXqO_8B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the target variable is 'age', modify this according to your dataset\n",
        "X = df.drop('age', axis=1)\n",
        "y = df['age']"
      ],
      "metadata": {
        "id": "yhDCAYD9PO2g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UzAUZVhEPVmO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression task\n",
        "])"
      ],
      "metadata": {
        "id": "6IyYa49xPXi4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error on Test Data: {loss}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKn5o7qoPaDD",
        "outputId": "07c3b00f-71ed-45fb-d68d-7c3d7fed706a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 62ms/step - loss: 3010.9070 - val_loss: 2909.5403\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2945.9775 - val_loss: 2840.9785\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2878.7832 - val_loss: 2766.1174\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2804.2014 - val_loss: 2680.6228\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2716.7124 - val_loss: 2579.3884\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2611.1479 - val_loss: 2459.4263\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2487.3025 - val_loss: 2316.8613\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2341.0137 - val_loss: 2153.0298\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2175.2676 - val_loss: 1968.9135\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1988.4465 - val_loss: 1769.1304\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1786.0088 - val_loss: 1554.1204\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1573.2776 - val_loss: 1330.6965\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1351.3453 - val_loss: 1110.3193\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1130.3540 - val_loss: 897.7953\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 919.5850 - val_loss: 704.7835\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 725.8222 - val_loss: 542.3461\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 562.1599 - val_loss: 414.9529\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 430.7060 - val_loss: 323.6622\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 334.1745 - val_loss: 264.3656\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 267.1559 - val_loss: 230.9337\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 227.8850 - val_loss: 212.6073\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 201.3898 - val_loss: 199.7649\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 185.7202 - val_loss: 190.2467\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 175.2079 - val_loss: 183.4120\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 165.9892 - val_loss: 175.8519\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 158.8466 - val_loss: 167.7527\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 151.5771 - val_loss: 160.8881\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 144.9082 - val_loss: 155.8866\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 139.2660 - val_loss: 152.6697\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 133.8483 - val_loss: 146.2264\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 129.1126 - val_loss: 141.2541\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 124.1352 - val_loss: 137.3941\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 120.1785 - val_loss: 133.7418\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 116.2696 - val_loss: 129.8425\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 113.0345 - val_loss: 128.1750\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 109.6712 - val_loss: 123.5773\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 106.3014 - val_loss: 120.8269\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 103.5213 - val_loss: 120.1092\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.7582 - val_loss: 118.0728\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 98.2228 - val_loss: 117.2212\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 96.2708 - val_loss: 117.4827\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 93.9987 - val_loss: 113.7582\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 91.6281 - val_loss: 112.7562\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 89.9147 - val_loss: 111.5054\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 88.1553 - val_loss: 111.1602\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 86.3968 - val_loss: 110.1031\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 85.0433 - val_loss: 108.8630\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 83.4138 - val_loss: 110.0831\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 81.9242 - val_loss: 110.3881\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 80.7453 - val_loss: 110.2079\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 110.2079\n",
            "Mean Squared Error on Test Data: 110.20787811279297\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    }
  ]
}